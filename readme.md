ğŸ“Š Churn Prediction API 

A production-ready FastAPI service for predicting customer churn.
Includes single prediction, batch prediction, CORS support, logging, schemas, and real-time deployment using Docker + Render.

ğŸš€ Features

âœ” Model-loaded churn prediction
âœ” /predict for single record
âœ” /predict/batch for multiple records
âœ” Pydantic validation
âœ” Production logging
âœ” Clean folder structure
âœ” Dockerized deployment
âœ” Render hosting (free tier supported)

ğŸ“‚ Project Structure

churn_project/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # FastAPI app & routes
â”‚   â”œâ”€â”€ schemas.py            # Request/response models
â”‚   â”œâ”€â”€ model_utils.py        # Model loading & prediction
â”‚   â”œâ”€â”€ logger.py             # Application logs
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ churn_model.pkl       # Trained ML model
â”‚
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ Dockerfile                # Deployment container
â””â”€â”€ Procfile (optional)       # Render start command

ğŸ§  Model

The API loads a pre-trained binary classifier (churn_model.pkl).
The model predicts whether a customer will churn (1) or not churn (0) and returns:

numerical prediction

human-readable label

probability of prediction

ğŸ“Œ API Endpoints
1. Health Check

GET /health

{
  "status": "ok"
}

2. Single Prediction

POST /predict

Request Body
{
  "tenure": 5,
  "monthly_charges": 65.4,
  "total_charges": 324.5,
  "senior_citizen": 0,
  "gender": "Male",
  "internet_service": "Fiber optic"
}

Response
{
  "prediction": 1,
  "prediction_label": "Churn",
  "probability_of_prediction": 0.82,
  "probabilities": [0.18, 0.82]
}

3. Batch Prediction

POST /predict/batch

Request Body:
{
  "customers": [
    { ...customer1 },
    { ...customer2 }
  ]
}

ğŸ³ Docker Deployment

Build: docker build -t churn-api .

Run: docker run -p 8000:8000 churn-api


â˜ï¸ Render Deployment

Push project to GitHub
Create a new Web Service on Render
Set Start Command:
uvicorn app.main:app --host 0.0.0.0 --port 8000

Deploy(Render)

ğŸš€ Live API URL
ğŸ”— https://churn-project-ekvu.onrender.com

Swagger Docs:
ğŸ‘‰ https://churn-project-ekvu.onrender.com/docs


ğŸ› ï¸ Tech Stack

FastAPI
Python 3.11.11
NumPy
pandas
Scikit-Learn
Uvicorn
Docker
Render Cloud

ğŸ¯ Author

Lalit Shinde (Lucky)
B.Tech AIML | Machine Learning Engineer
âœ‰ GitHub: 


