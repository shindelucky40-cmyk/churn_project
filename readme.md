ğŸ“Š Churn Prediction API 

A production-ready FastAPI service for predicting customer churn.
Includes single prediction, batch prediction, CORS support, logging, schemas, and real-time deployment using Docker + Render.

ğŸš€ Features

âœ” Model-loaded churn prediction
âœ” /predict for single record
âœ” /predict/batch for multiple records
âœ” Pydantic validation
âœ” Production logging
âœ” Clean folder structure
âœ” Dockerized deployment
âœ” Render hosting (free tier supported)

ğŸ“‚ Project Structure

churn_project/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # FastAPI app & routes
â”‚   â”œâ”€â”€ schemas.py            # Request/response models
â”‚   â”œâ”€â”€ model_utils.py        # Model loading & prediction
â”‚   â”œâ”€â”€ logger.py             # Application logs
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ churn_model.pkl       # Trained ML model
â”‚
â”œâ”€â”€ requirements.txt          # Project dependencies
â”œâ”€â”€ Dockerfile                # Deployment container
â””â”€â”€ Procfile (optional)       # Render start command

ğŸ§  Model

The API loads a pre-trained binary classifier (churn_model.pkl).
The model predicts whether a customer will churn (1) or not churn (0) and returns:

numerical prediction

human-readable label

probability of prediction

ğŸ“Œ API Endpoints
1. Health Check

GET /health

{
  "status": "ok"
}

2. Single Prediction

POST /predict

Request Body
{
  "tenure": 5,
  "monthly_charges": 65.4,
  "total_charges": 324.5,
  "senior_citizen": 0,
  "gender": "Male",
  "internet_service": "Fiber optic"
}

Response
{
  "prediction": 1,
  "prediction_label": "Churn",
  "probability_of_prediction": 0.82,
  "probabilities": [0.18, 0.82]
}

3. Batch Prediction

POST /predict/batch

Request Body:
{
  "customers": [
    { ...customer1 },
    { ...customer2 }
  ]
}

ğŸ³ Docker Deployment

Build: docker build -t churn-api .

Run: docker run -p 8000:8000 churn-api


â˜ï¸ Render Deployment

Push project to GitHub
Create a new Web Service on Render
Set Start Command:
uvicorn app.main:app --host 0.0.0.0 --port 8000

Deploy(Render)

ğŸš€ Live API URL
ğŸ”— https://churn-project-ekvu.onrender.com

Swagger Docs:
ğŸ‘‰ https://churn-project-ekvu.onrender.com/docs


ğŸ› ï¸ Tech Stack

FastAPI
Python 3.11.11
NumPy
pandas
Scikit-Learn
Uvicorn
Docker
Render Cloud

ğŸ¯ Author

Lalit Shinde (Lucky)
B.Tech AIML | Machine Learning Engineer
âœ‰ GitHub: 


Churn Prediction API

A production-ready FastAPI service for customer churn prediction.
Includes single/batch prediction, validation, logging, Dockerization, and Render deployment.

Features

FastAPI-based prediction service

/predict â†’ single prediction

/predict/batch â†’ batch prediction

Pydantic models

Logging included

Docker support

Deployed on Render

Project Structure
churn_project/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # FastAPI app and routes
â”‚   â”œâ”€â”€ schemas.py           # Request/response models
â”‚   â”œâ”€â”€ model_utils.py       # Model loading and prediction
â”‚   â”œâ”€â”€ logger.py            # Logging setup
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ churn_model.pkl      # Trained ML model
â”‚
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ Dockerfile               # Docker configuration
â””â”€â”€ Procfile (optional)      # Render start command

API Endpoints
Health Check
GET /health


Response:

{ "status": "ok" }

Single Prediction
POST /predict


Example request:

{
  "tenure": 5,
  "monthly_charges": 65.4,
  "total_charges": 324.5,
  "senior_citizen": 0,
  "gender": "Male",
  "internet_service": "Fiber optic"
}


Example response:

{
  "prediction": 1,
  "prediction_label": "Churn",
  "probability_of_prediction": 0.82,
  "probabilities": [0.18, 0.82]
}

Batch Prediction
POST /predict/batch


Format:

{
  "customers": [
    { ... },
    { ... }
  ]
}

Docker

Build:

docker build -t churn-api .


Run:

docker run -p 8000:8000 churn-api

Render Deployment

Push repo to GitHub

Create Render Web Service

Start command:

uvicorn app.main:app --host 0.0.0.0 --port 8000


Deploy

Live URLs

API:
https://churn-project-ekvu.onrender.com

Docs:
https://churn-project-ekvu.onrender.com/docs

Tech Stack

FastAPI

Python 3.11

Scikit-Learn

Pandas

NumPy

Uvicorn

Docker

Render

Author

Lalit Shinde (Lucky)
Machine Learning Engineer â€” AIML

